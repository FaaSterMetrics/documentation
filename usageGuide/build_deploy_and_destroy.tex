\documentclass[../main.tex]{subfiles}
\begin{document}

% TODO: This is getting too long
\section{Build, Deploy, Logs and Destroy}\label{sec:builddeploylogsanddestroy}
In this section, the build, deployment, log fetching and finally destruction process of an experiment is explained.

Please ensure that your `experiment.json' file is configured correctly (\Cref{sec:experimentConfig}). 
All required providers also need to be set up correctly (\Cref{sec:providersetup}).

\subsection{Build}\label{sec:build}
Before deploying the experiment to the different cloud providers, 
it is essential to build the application. 
This step compiles the JavaScript files and generates the deployment artifacts. 
These artifacts are essentially .zip files containing the compiled code and the assets. 
They are needed in the following deployment step. 

For compiling the JavaScript files, ncc\footnote{\url{https://github.com/vercel/ncc}} 
from vercel\footnote{\url{https://vercel.com}} is used.
It allows us to build a single JavaScript file containing the function code and all npm dependencies.

To build your experiment run \texttt{npm run build <experiment name>}.

\subsection{Deploy}\label{sec:deploy}
If the experiment is now successfully built, 
the next step is to deploy the functions and services to the cloud providers. 
A service is for example a key-value database like redis\footnote{\url{https://redis.io}}. 

To interact with the different cloud providers, we use `terraform'%
\footnote{\url{https://www.terraform.io/}} from HashiCorp\footnote{\url{https://www.hashicorp.com/}}. 
Terraform is a cloud infrastructure automation tool that allows us to create, 
update, or delete cloud resources with declarative configuration files. 
This functionality is essential in terms of reproducibility and predictability.
The developed deployment script detects the cloud providers that need to be provisioned by `terraform'
and executes the matching `terraform' configuration files.

To deploy your experiment run \texttt{npm run deploy <experiment name>}.

\subsection{Logs}\label{sec:logs}
After you've conducted an experiment you might want to fetch the logs 
from all the providers you've deployed resources to. 
This tasks iterates through all the providers you've deployed resources on and fetches their raw, 
unprocessed logs to \texttt{logs/<experiment name>/<current date>/<provider>.log}

To fetch the logs from your experiment run \texttt{npm run logs <experiment name>}.

\textit{Note:} When fetching logs be sure to do so \textit{before} destroying the experiment.

\subsection{Destroy}\label{sec:destroy}
After you're done experimenting or want a clean state, 
it is time to release all the allocated resources from the cloud providers.
This task will completely remove all resources allocated by the in the deploy step. 

This command should be used after being done experimenting to avoid unnecessary costs 
and clutter on the cloud providers.
It should also be used in between experiment runs to ensure a clean state.

However, running \texttt{npm run deploy} again while the experiment is already deployed will 
automatically free any unused/outdated resources.
Thus, during development it is often not necessary to destroy the experiment before deploying again.

To destroy your experiment run \texttt{npm run destroy}.


\end{document}
